{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "#from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 101\n",
    "img_size_target = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    print('***************************1***********************************************')\n",
    "    # 101 -> 50\n",
    "    print('101 -> 50')\n",
    "    print('in {}'.format(input_layer.shape))\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    print('in to conv{}'.format(conv1.shape))\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    print('1 res {}'.format(conv1.shape))\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    print('2 res{}'.format(conv1.shape))\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    print('max{}'.format(pool1.shape))\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "    print('drp- out{}'.format(pool1.shape))\n",
    "    \n",
    "    print('***************************2***********************************************')\n",
    "    # 50 -> 25\n",
    "    print('in {}'.format(pool1.shape))\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    print('in to conv{}'.format(conv2.shape))\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    print('1 res{}'.format(conv2.shape))\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    print('2 res {}'.format(conv2.shape))\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    print('max {}'.format(pool2.shape))\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "    print('drp-out {}'.format(pool2.shape))\n",
    "    \n",
    "    print('***************************3***********************************************')\n",
    "    # 25 -> 12\n",
    "    print('in{}'.format(pool2.shape))\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    print('in to conv{}'.format(conv3.shape))\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    print('1 res{}'.format(conv3.shape))\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    print('2 res{}'.format(conv3.shape))\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    print('max{}'.format(pool3.shape))\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "    print('drp - out{}'.format(pool3.shape))\n",
    "    \n",
    "    print('***************************4***********************************************')\n",
    "    # 12 -> 6\n",
    "    print('in {}'.format(pool3.shape))\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    print('in to conv{}'.format(conv4.shape))\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    print('1 res{}'.format(conv4.shape))\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    print('2 res {}'.format(conv4.shape))\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    print('max {}'.format(pool4.shape))\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "    print('drp - out {}'.format(pool4.shape))\n",
    "    \n",
    "    print('***************************middle***********************************************')\n",
    "    # Middle\n",
    "    print('in {}'.format(pool4.shape))\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    print('in to conv{}'.format(convm.shape))\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    print('1 res{}'.format(convm.shape))\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    print('2 res{}'.format(convm.shape))\n",
    "    \n",
    "    print('***************************4 up***********************************************')\n",
    "    # 6 -> 12\n",
    "    print('in{}'.format(convm.shape))\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    print('in to T{}'.format(deconv4.shape))\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    print('concat T conv4{}'.format(uconv4.shape))\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    print('drp {}'.format(uconv4.shape))\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    print('drp to conv{}'.format(uconv4.shape))\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    print('1 res{}'.format(uconv4.shape))\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    print('2 res{}'.format(uconv4.shape))\n",
    "    \n",
    "    print('***************************3 up***********************************************')\n",
    "    # 12 -> 25\n",
    "    print('in {}'.format(uconv4.shape))\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    print('in to T{}'.format(deconv3.shape))\n",
    "    uconv3 = concatenate([deconv3, conv3])  \n",
    "    print('concat T conv3{}'.format(uconv3.shape))\n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    print('drp {}'.format(uconv3.shape))\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    print('drp to conv{}'.format(uconv3.shape))\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    print('1 res {}'.format(uconv3.shape))\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "    print('2 res {}'.format(uconv3.shape))\n",
    "\n",
    "    print('***************************2 up***********************************************')\n",
    "    # 25 -> 50\n",
    "    print('in {}'.format(uconv3.shape))\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    print('in to T{}'.format(deconv2.shape))\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    print('concat T conv2{}'.format(uconv2.shape))\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    print('drp {}'.format(uconv2.shape))\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    print('drp - conv{}'.format(uconv2.shape))\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    print('res 1{}'.format(uconv2.shape))\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    print('res2 {}'.format(uconv2.shape))\n",
    "    \n",
    "    print('***************************1 up***********************************************')\n",
    "    # 50 -> 101\n",
    "    print('in {}'.format(uconv2.shape))\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    print('in to T{}'.format(deconv1.shape))\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    print('concat T conv 1{}'.format(uconv1.shape))\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    print('drp {}'.format(uconv1.shape))\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    print('drp to conv{}'.format(uconv1.shape))\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    print('res 1{}'.format(uconv1.shape))\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    print('res 2 {}'.format(uconv1.shape))\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    print('out no act{}'.format(output_layer_noActi.shape))\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    print('out with act {}'.format(output_layer.shape))\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************1***********************************************\n",
      "101 -> 50\n",
      "in (?, 101, 101, 1)\n",
      "in to conv(?, 101, 101, 16)\n",
      "1 res (?, 101, 101, 16)\n",
      "2 res(?, 101, 101, 16)\n",
      "max(?, 50, 50, 16)\n",
      "drp- out(?, 50, 50, 16)\n",
      "***************************2***********************************************\n",
      "in (?, 50, 50, 16)\n",
      "in to conv(?, 50, 50, 32)\n",
      "1 res(?, 50, 50, 32)\n",
      "2 res (?, 50, 50, 32)\n",
      "max (?, 25, 25, 32)\n",
      "drp-out (?, 25, 25, 32)\n",
      "***************************3***********************************************\n",
      "in(?, 25, 25, 32)\n",
      "in to conv(?, 25, 25, 64)\n",
      "1 res(?, 25, 25, 64)\n",
      "2 res(?, 25, 25, 64)\n",
      "max(?, 12, 12, 64)\n",
      "drp - out(?, 12, 12, 64)\n",
      "***************************4***********************************************\n",
      "in (?, 12, 12, 64)\n",
      "in to conv(?, 12, 12, 128)\n",
      "1 res(?, 12, 12, 128)\n",
      "2 res (?, 12, 12, 128)\n",
      "max (?, 6, 6, 128)\n",
      "drp - out (?, 6, 6, 128)\n",
      "***************************middle***********************************************\n",
      "in (?, 6, 6, 128)\n",
      "in to conv(?, 6, 6, 256)\n",
      "1 res(?, 6, 6, 256)\n",
      "2 res(?, 6, 6, 256)\n",
      "***************************4 up***********************************************\n",
      "in(?, 6, 6, 256)\n",
      "in to T(?, ?, ?, 128)\n",
      "concat T conv4(?, 12, 12, 256)\n",
      "drp (?, 12, 12, 256)\n",
      "drp to conv(?, 12, 12, 128)\n",
      "1 res(?, 12, 12, 128)\n",
      "2 res(?, 12, 12, 128)\n",
      "***************************3 up***********************************************\n",
      "in (?, 12, 12, 128)\n",
      "in to T(?, ?, ?, 64)\n",
      "concat T conv3(?, 25, 25, 128)\n",
      "drp (?, 25, 25, 128)\n",
      "drp to conv(?, 25, 25, 64)\n",
      "1 res (?, 25, 25, 64)\n",
      "2 res (?, 25, 25, 64)\n",
      "***************************2 up***********************************************\n",
      "in (?, 25, 25, 64)\n",
      "in to T(?, ?, ?, 32)\n",
      "concat T conv2(?, 50, 50, 64)\n",
      "drp (?, 50, 50, 64)\n",
      "drp - conv(?, 50, 50, 32)\n",
      "res 1(?, 50, 50, 32)\n",
      "res2 (?, 50, 50, 32)\n",
      "***************************1 up***********************************************\n",
      "in (?, 50, 50, 32)\n",
      "in to T(?, ?, ?, 16)\n",
      "concat T conv 1(?, 101, 101, 32)\n",
      "drp (?, 101, 101, 32)\n",
      "drp to conv(?, 101, 101, 16)\n",
      "res 1(?, 101, 101, 16)\n",
      "res 2 (?, 101, 101, 16)\n",
      "out no act(?, 101, 101, 1)\n",
      "out with act (?, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.5)\n",
    "\n",
    "model1 = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model1(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    print('***************************1***********************************************')\n",
    "    # 101 -> 50\n",
    "    print('101 -> 50')\n",
    "    print('in {}'.format(input_layer.shape))\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    print('in to conv{}'.format(conv1.shape))\n",
    "    conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    print('1 res {}'.format(conv1.shape))\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    print('2 res{}'.format(conv1.shape))\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    print('max{}'.format(pool1.shape))\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "    print('drp- out{}'.format(pool1.shape))\n",
    "    \n",
    "    print('***************************2***********************************************')\n",
    "    # 50 -> 25\n",
    "    print('in {}'.format(pool1.shape))\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    print('in to conv{}'.format(conv2.shape))\n",
    "    conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    print('1 res{}'.format(conv2.shape))\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    print('2 res {}'.format(conv2.shape))\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    print('max {}'.format(pool2.shape))\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "    print('drp-out {}'.format(pool2.shape))\n",
    "    \n",
    "    print('***************************3***********************************************')\n",
    "    # 25 -> 12\n",
    "    print('in{}'.format(pool2.shape))\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    print('in to conv{}'.format(conv3.shape))\n",
    "    conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    print('1 res{}'.format(conv3.shape))\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    print('2 res{}'.format(conv3.shape))\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    print('max{}'.format(pool3.shape))\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "    print('drp - out{}'.format(pool3.shape))\n",
    "    \n",
    "    print('***************************4***********************************************')\n",
    "    # 12 -> 6\n",
    "    print('in {}'.format(pool3.shape))\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    print('in to conv{}'.format(conv4.shape))\n",
    "    conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    print('1 res{}'.format(conv4.shape))\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    print('2 res {}'.format(conv4.shape))\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    print('max {}'.format(pool4.shape))\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "    print('drp - out {}'.format(pool4.shape))\n",
    "    \n",
    "    print('***************************middle***********************************************')\n",
    "    # Middle\n",
    "    print('in {}'.format(pool4.shape))\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    print('in to conv{}'.format(convm.shape))\n",
    "    convm = residual_block(convm,start_neurons * 16)\n",
    "    print('1 res{}'.format(convm.shape))\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    print('2 res{}'.format(convm.shape))\n",
    "    \n",
    "    print('***************************4 up***********************************************')\n",
    "    # 6 -> 12\n",
    "    print('in{}'.format(convm.shape))\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    print('in to T{}'.format(deconv4.shape))\n",
    "    print('conv shape {}'.format(conv4))\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    print('concat T conv4{}'.format(uconv4.shape))\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    print('drp {}'.format(uconv4.shape))\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    print('drp to conv{}'.format(uconv4.shape))\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    print('1 res{}'.format(uconv4.shape))\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    print('2 res{}'.format(uconv4.shape))\n",
    "    \n",
    "    print('***************************3 up***********************************************')\n",
    "    # 12 -> 25\n",
    "    print('in {}'.format(uconv4.shape))\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    print('in to T{}'.format(deconv3.shape))\n",
    "    print('conv shape {}'.format(conv3))\n",
    "    uconv3 = concatenate([deconv3, conv3])  \n",
    "    print('concat T conv3{}'.format(uconv3.shape))\n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    print('drp {}'.format(uconv3.shape))\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    print('drp to conv{}'.format(uconv3.shape))\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    print('1 res {}'.format(uconv3.shape))\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "    print('2 res {}'.format(uconv3.shape))\n",
    "\n",
    "    print('***************************2 up***********************************************')\n",
    "    # 25 -> 50\n",
    "    print('in {}'.format(uconv3.shape))\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    print('in to T{}'.format(deconv2.shape))\n",
    "    print('conv shape {}'.format(conv2))\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    print('concat T conv2{}'.format(uconv2.shape))\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    print('drp {}'.format(uconv2.shape))\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    print('drp - conv{}'.format(uconv2.shape))\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    print('res 1{}'.format(uconv2.shape))\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    print('res2 {}'.format(uconv2.shape))\n",
    "    \n",
    "    print('***************************1 up***********************************************')\n",
    "    # 50 -> 101\n",
    "    print('in {}'.format(uconv2.shape))\n",
    "#     deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    print('in to T{}'.format(deconv1.shape))\n",
    "    print('conv shape {}'.format(conv1))\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    print('concat T conv 1{}'.format(uconv1.shape))\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    print('drp {}'.format(uconv1.shape))\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    print('drp to conv{}'.format(uconv1.shape))\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    print('res 1{}'.format(uconv1.shape))\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    print('res 2 {}'.format(uconv1.shape))\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    print('out no act{}'.format(output_layer_noActi.shape))\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    print('out with act {}'.format(output_layer.shape))\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************1***********************************************\n",
      "101 -> 50\n",
      "in (?, 101, 101, 1)\n",
      "in to conv(?, 101, 101, 16)\n",
      "1 res (?, 101, 101, 16)\n",
      "2 res(?, 101, 101, 16)\n",
      "max(?, 50, 50, 16)\n",
      "drp- out(?, 50, 50, 16)\n",
      "***************************2***********************************************\n",
      "in (?, 50, 50, 16)\n",
      "in to conv(?, 50, 50, 32)\n",
      "1 res(?, 50, 50, 32)\n",
      "2 res (?, 50, 50, 32)\n",
      "max (?, 25, 25, 32)\n",
      "drp-out (?, 25, 25, 32)\n",
      "***************************3***********************************************\n",
      "in(?, 25, 25, 32)\n",
      "in to conv(?, 25, 25, 64)\n",
      "1 res(?, 25, 25, 64)\n",
      "2 res(?, 25, 25, 64)\n",
      "max(?, 12, 12, 64)\n",
      "drp - out(?, 12, 12, 64)\n",
      "***************************4***********************************************\n",
      "in (?, 12, 12, 64)\n",
      "in to conv(?, 12, 12, 128)\n",
      "1 res(?, 12, 12, 128)\n",
      "2 res (?, 12, 12, 128)\n",
      "max (?, 6, 6, 128)\n",
      "drp - out (?, 6, 6, 128)\n",
      "***************************middle***********************************************\n",
      "in (?, 6, 6, 128)\n",
      "in to conv(?, 6, 6, 256)\n",
      "1 res(?, 6, 6, 256)\n",
      "2 res(?, 6, 6, 256)\n",
      "***************************4 up***********************************************\n",
      "in(?, 6, 6, 256)\n",
      "in to T(?, ?, ?, 128)\n",
      "conv shape Tensor(\"activation_278/Relu:0\", shape=(?, 12, 12, 128), dtype=float32)\n",
      "concat T conv4(?, 12, 12, 256)\n",
      "drp (?, 12, 12, 256)\n",
      "drp to conv(?, 12, 12, 128)\n",
      "1 res(?, 12, 12, 128)\n",
      "2 res(?, 12, 12, 128)\n",
      "***************************3 up***********************************************\n",
      "in (?, 12, 12, 128)\n",
      "in to T(?, ?, ?, 64)\n",
      "conv shape Tensor(\"activation_273/Relu:0\", shape=(?, 25, 25, 64), dtype=float32)\n",
      "concat T conv3(?, 25, 25, 128)\n",
      "drp (?, 25, 25, 128)\n",
      "drp to conv(?, 25, 25, 64)\n",
      "1 res (?, 25, 25, 64)\n",
      "2 res (?, 25, 25, 64)\n",
      "***************************2 up***********************************************\n",
      "in (?, 25, 25, 64)\n",
      "in to T(?, ?, ?, 32)\n",
      "conv shape Tensor(\"activation_268/Relu:0\", shape=(?, 50, 50, 32), dtype=float32)\n",
      "concat T conv2(?, 50, 50, 64)\n",
      "drp (?, 50, 50, 64)\n",
      "drp - conv(?, 50, 50, 32)\n",
      "res 1(?, 50, 50, 32)\n",
      "res2 (?, 50, 50, 32)\n",
      "***************************1 up***********************************************\n",
      "in (?, 50, 50, 32)\n",
      "in to T(?, ?, ?, 16)\n",
      "conv shape Tensor(\"activation_263/Relu:0\", shape=(?, 101, 101, 16), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 100, 100, 16), (None, 101, 101, 16)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cf70f0c47a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_size_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moutput_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-57a2c5f58df1>\u001b[0m in \u001b[0;36mbuild_model1\u001b[0;34m(input_layer, start_neurons, DropoutRatio)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'in to T{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'conv shape {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0muconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'concat T conv 1{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condavenv/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    639\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condavenv/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m                                          \u001b[0;34m'You can build it manually via: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/condavenv/lib/python3.6/site-packages/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    352\u001b[0m                              \u001b[0;34m'inputs with matching shapes '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                              \u001b[0;34m'except for the concat axis. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 100, 100, 16), (None, 101, 101, 16)]"
     ]
    }
   ],
   "source": [
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model1(input_layer, 16,0.5)\n",
    "\n",
    "model2 = Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
