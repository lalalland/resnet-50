{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Conv2DTranspose,GlobalAveragePooling2D, Reshape, Dense, multiply, Permute\n",
    "from keras.layers import Input, add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(blockInput)\n",
    "    x = convolution_block(x, num_filters, (3,3) )\n",
    "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
    "    x = Add()([x, blockInput])\n",
    "    if batch_activate:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def squeeze_excite_block(input, ratio=16):\n",
    "    init = input\n",
    "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
    "    filters = init._keras_shape[channel_axis]\n",
    "    se_shape = (1, 1, filters)\n",
    "\n",
    "    se = GlobalAveragePooling2D()(init)\n",
    "    se = Reshape(se_shape)(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        se = Permute((3, 1, 2))(se)\n",
    "\n",
    "    x = multiply([init, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, filters=64, n_block=3, kernel_size=(3, 3), activation='relu'):\n",
    "    skip = []\n",
    "    for i in range(n_block):\n",
    "        print('*********************encoder {}******************'.format(i+1))\n",
    "        print('input {}'.format(x.shape))\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=None, padding='same')(x)\n",
    "        print('conv no act {}'.format(x.shape))\n",
    "#         x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = residual_block(x,filters * 2**i)\n",
    "        print('conv 1 {}'.format(x.shape))\n",
    "#         x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = residual_block(x,filters * 2**i,True)\n",
    "        print('conv 2 {}'.format(x.shape))\n",
    "        x = squeeze_excite_block(x, ratio=16)\n",
    "        print('squeeze{}'.format(x.shape))\n",
    "        skip.append(x)\n",
    "        x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n",
    "#         x = Dropout(DropoutRatio/2)(x)\n",
    "        print('Max {}'.format(x.shape))\n",
    "        print('**************************************************************************')\n",
    "    return x, skip\n",
    "\n",
    "\n",
    "def bottleneck(x, filters_bottleneck, mode='cascade', depth=6,\n",
    "               kernel_size=(3, 3), activation='relu'):\n",
    "    dilated_layers = []\n",
    "    print('*********************************middle*********************************')\n",
    "    print('input {}'.format(x.shape))\n",
    "    if mode == 'cascade':  # used in the competition\n",
    "        print('cascade dilatation')\n",
    "        for i in range(depth):\n",
    "            \n",
    "            x = Conv2D(filters_bottleneck, kernel_size,\n",
    "                       activation=activation, padding='same', dilation_rate=2**i)(x)\n",
    "           \n",
    "            dilated_layers.append(x)\n",
    "            print('conv dilatation {} {}'.format(i,x.shape))\n",
    "        return add(dilated_layers)\n",
    "    elif mode == 'parallel':  # Like \"Atrous Spatial Pyramid Pooling\"\n",
    "        print('parallel dilatation')\n",
    "        for i in range(depth):\n",
    "            dilated_layers.append(\n",
    "                Conv2D(filters_bottleneck, kernel_size,\n",
    "                       activation=activation, padding='same', dilation_rate=2**i)(x)\n",
    "            )\n",
    "            print('conv dilatation {} {}'.format(i,Conv2D(filters_bottleneck, kernel_size,\n",
    "                       activation=activation, padding='same', dilation_rate=2**i)(x).shape))\n",
    "        return add(dilated_layers)\n",
    "\n",
    "\n",
    "def decoder(x, skip, filters, n_block=3, kernel_size=(3, 3), activation='relu'):\n",
    "    \n",
    "    \n",
    "    for i in reversed(range(n_block)):\n",
    "        print('*********************************decoder{}*********************************'.format(i+1))\n",
    "        print('input {}'.format(x.shape))\n",
    "#         x = UpSampling2D(size=(2, 2))(x)\n",
    "        print('upsampling {}'.format(x.shape))\n",
    "        print('filters {}'.format(filters * 2**i))\n",
    "        print('kernel {}'.format(kernel_size))\n",
    "        if i == 3 or i == 1:\n",
    "            x = Conv2DTranspose(filters * 2**i, kernel_size, strides=(2, 2), padding=\"same\")(x)\n",
    "# #             x = Conv2D(filters * 2**i, kernel_size, activation=None,strides=(2, 2), padding='valid')(x)\n",
    "# #             x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "#             x = Conv2DTranspose(filters * 2**i, kernel_size, strides=(2, 2), padding=\"same\")(x)\n",
    "        else:\n",
    "            x = Conv2DTranspose(filters * 2**i, kernel_size, strides=(2, 2), padding=\"valid\")(x)\n",
    "#         print('conv 1 {}'.format(x.shape))\n",
    "        print('skip {}'.format(skip[i].shape))\n",
    "        print('conv T {}'.format(x))\n",
    "        x = concatenate([skip[i], x])\n",
    "        print('concat {}'.format(x.shape))\n",
    "        x = Conv2D(filters * 2**i, kernel_size, activation=None, padding='same')(x)\n",
    "        print('conv1 no activation {}'.format(x.shape))\n",
    "#         x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = residual_block(x,filters * 2**i)\n",
    "        print('conv2 {}'.format(x.shape))\n",
    "#         x = Conv2D(filters * 2**i, kernel_size, activation=activation, padding='same')(x)\n",
    "        x = residual_block(x,filters * 2**i, True)\n",
    "        print('conv3 {}'.format(x.shape))\n",
    "        x = squeeze_excite_block(x, ratio=16)\n",
    "        print('squeeze{}'.format(x.shape))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dilated_unet(\n",
    "        input_shape=(101, 101, 1),\n",
    "        mode='cascade',\n",
    "        filters=16,\n",
    "        n_block=4,\n",
    "        lr=0.0001,\n",
    "        loss='bce_dice_loss',\n",
    "        n_class=1\n",
    "):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    enc, skip = encoder(inputs, filters, n_block)\n",
    "    bottle = bottleneck(enc, filters_bottleneck=filters * 2**n_block, mode=mode)\n",
    "    dec = decoder(bottle, skip, filters, n_block)\n",
    "    classify = Conv2D(n_class, (1, 1), activation='sigmoid')(dec)\n",
    "    print('last {}'.format(classify.shape))\n",
    "    model = Model(inputs=inputs, outputs=classify)\n",
    "#     model.compile(optimizer=RMSprop(lr), loss=loss, metrics=[dice_coef])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************encoder 1******************\n",
      "input (?, 101, 101, 3)\n",
      "conv no act (?, 101, 101, 16)\n",
      "conv 1 (?, 101, 101, 16)\n",
      "conv 2 (?, 101, 101, 16)\n",
      "squeeze(?, 101, 101, 16)\n",
      "Max (?, 50, 50, 16)\n",
      "**************************************************************************\n",
      "*********************encoder 2******************\n",
      "input (?, 50, 50, 16)\n",
      "conv no act (?, 50, 50, 32)\n",
      "conv 1 (?, 50, 50, 32)\n",
      "conv 2 (?, 50, 50, 32)\n",
      "squeeze(?, 50, 50, 32)\n",
      "Max (?, 25, 25, 32)\n",
      "**************************************************************************\n",
      "*********************encoder 3******************\n",
      "input (?, 25, 25, 32)\n",
      "conv no act (?, 25, 25, 64)\n",
      "conv 1 (?, 25, 25, 64)\n",
      "conv 2 (?, 25, 25, 64)\n",
      "squeeze(?, 25, 25, 64)\n",
      "Max (?, 12, 12, 64)\n",
      "**************************************************************************\n",
      "*********************encoder 4******************\n",
      "input (?, 12, 12, 64)\n",
      "conv no act (?, 12, 12, 128)\n",
      "conv 1 (?, 12, 12, 128)\n",
      "conv 2 (?, 12, 12, 128)\n",
      "squeeze(?, 12, 12, 128)\n",
      "Max (?, 6, 6, 128)\n",
      "**************************************************************************\n",
      "*********************************middle*********************************\n",
      "input (?, 6, 6, 128)\n",
      "cascade dilatation\n",
      "conv dilatation 0 (?, 6, 6, 256)\n",
      "conv dilatation 1 (?, 6, 6, 256)\n",
      "conv dilatation 2 (?, 6, 6, 256)\n",
      "conv dilatation 3 (?, 6, 6, 256)\n",
      "conv dilatation 4 (?, 6, 6, 256)\n",
      "conv dilatation 5 (?, 6, 6, 256)\n",
      "*********************************decoder4*********************************\n",
      "input (?, 6, 6, 256)\n",
      "upsampling (?, 6, 6, 256)\n",
      "filters 128\n",
      "kernel (3, 3)\n",
      "skip (?, 12, 12, 128)\n",
      "conv T Tensor(\"conv2d_transpose_1/BiasAdd:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "concat (?, 12, 12, 256)\n",
      "conv1 no activation (?, 12, 12, 128)\n",
      "conv2 (?, 12, 12, 128)\n",
      "conv3 (?, 12, 12, 128)\n",
      "squeeze(?, 12, 12, 128)\n",
      "*********************************decoder3*********************************\n",
      "input (?, 12, 12, 128)\n",
      "upsampling (?, 12, 12, 128)\n",
      "filters 64\n",
      "kernel (3, 3)\n",
      "skip (?, 25, 25, 64)\n",
      "conv T Tensor(\"conv2d_transpose_2/BiasAdd:0\", shape=(?, ?, ?, 64), dtype=float32)\n",
      "concat (?, 25, 25, 128)\n",
      "conv1 no activation (?, 25, 25, 64)\n",
      "conv2 (?, 25, 25, 64)\n",
      "conv3 (?, 25, 25, 64)\n",
      "squeeze(?, 25, 25, 64)\n",
      "*********************************decoder2*********************************\n",
      "input (?, 25, 25, 64)\n",
      "upsampling (?, 25, 25, 64)\n",
      "filters 32\n",
      "kernel (3, 3)\n",
      "skip (?, 50, 50, 32)\n",
      "conv T Tensor(\"conv2d_transpose_3/BiasAdd:0\", shape=(?, ?, ?, 32), dtype=float32)\n",
      "concat (?, 50, 50, 64)\n",
      "conv1 no activation (?, 50, 50, 32)\n",
      "conv2 (?, 50, 50, 32)\n",
      "conv3 (?, 50, 50, 32)\n",
      "squeeze(?, 50, 50, 32)\n",
      "*********************************decoder1*********************************\n",
      "input (?, 50, 50, 32)\n",
      "upsampling (?, 50, 50, 32)\n",
      "filters 16\n",
      "kernel (3, 3)\n",
      "skip (?, 101, 101, 16)\n",
      "conv T Tensor(\"conv2d_transpose_4/BiasAdd:0\", shape=(?, ?, ?, 16), dtype=float32)\n",
      "concat (?, 101, 101, 32)\n",
      "conv1 no activation (?, 101, 101, 16)\n",
      "conv2 (?, 101, 101, 16)\n",
      "conv3 (?, 101, 101, 16)\n",
      "squeeze(?, 101, 101, 16)\n",
      "last (?, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "modelcse = get_dilated_unet(\n",
    "        input_shape=(101, 101, 3),\n",
    "        mode='cascade',\n",
    "        filters=16,\n",
    "        n_class=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
